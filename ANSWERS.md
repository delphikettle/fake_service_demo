## Задание I

> Есть система, которая состоит из десятка сервисов с фоновым процессингом, общением через API и очереди сообщений. В общем, это некий pipeline, который на вход принимает один JSON, а на выходе отдает другой JSON. В процессе прохода по pipeline данные обогащаются, меняются и оседают в некоторых сервисах.
> 

> Каждую задачу обработки входных данных назовем операцией. По мере прохождения данных по pipeline статус у этой операции меняется и отражает текущее состояние обработки входных данных, на каком этапе она находится в тот или иной момент времени.
> 

> Есть сервис, который создан для отслеживания состояния той или иной операции обработки полученных на вход данных, назовем его Operation. Этот сервис хранит состояние операций в PostgreSQL. Некоторые из сервисов могут много и часто делать запросы по API и обновлять состояние операции в сервисе Operation. Фактически, у каждого набора входных данных есть запись в бд сервиса Operation, которая содержит сквозной уникальный id, статус и набор метаданных.
> 

### Опишите:

1. С какими проблемами можно столкнуться при таком способе хранения состояния обработки входных данных?
2. Что предпринять, если происходит “гонка” обновления данных операции в Operation и часть данных может перезаписываться старыми?
3. Как решить проблему с большим количеством UPDATE операций в PostgreSQL? И на каком уровне стоит ее решать?
4. Как можно спроектировать сервис для отслеживания состояния обработки входных JSON по всему pipeline, чтобы избежать подобных проблем? Какие минусы у вашего варианта реализации такого сервиса?

### Ответы:
1. С какими проблемами можно столкнуться при таком способе хранения состояния обработки входных данных?
   1. Race condition, ситуация когда сервис А получил инфу о операции, сервис Б сделал апдейт статуса этой операции, а сервис А уже после этого предпринимает решение основываясь на изначальном статусе
   2. Нет возможности наверняка отследить где на самом деле находится определенный json
   3. Отсутствует поддержка параллельной обработки, то есть например если в какой-то момент времени надо чтобы джсон обрабатывался на нескольких сервисах одновременно, статусы будут подразумевать только обработку на одном из этих сервисов
   4. Все сервисы ходят в одну базу данных, можно попробовать использовать распределенную бд, правда тогда становится ещё сложнее следить за консистентностью изменений

2. Что предпринять, если происходит “гонка” обновления данных операции в Operation и часть данных может перезаписываться старыми?

    1. Использовать Локи на бд уровне по записям и таким образом на момент обработки одним сервисом не давать обновлять такую-то запись, таким образом, другие не смогут создать гонку, изменив состояние
    2. Создать отдельный сервис с очередью обновлений, в который все другие сервисы будут сообщать об обновлениях из своих сервисов. Таким образом сервисы перестануть ходить в базу, а этот доп сервис с очередью может сам разруливать обновления
    3. Создать некий мастер сервис, который собственно и будет управлять пайплайном и следить за статусами и соответственно изменять их , в таком случае вообще никакой гонки не будет, всё будет управляться непосредственно с этого сервиса и соответственно он будет всегда знать реальное состояние операции и писать эту информацию в бд.
    
3. Как решить проблему с большим количеством UPDATE операций в PostgreSQL? И на каком уровне стоит ее решать?

    1. Если мы решим реализовать сервис так что апдейты летят только с одного сервиса (варианты 2 и 3 из прошлого пункта), то можно попробовать сделать это на уровне приложения. Например я помню давно пайплайн обработки событий продукта по безопасности и для него делал простой агрегатор близких вызовов, он собирал близкие по времени вызовы функций и объединял их в один, так например можно было объединить много апдейтов в один. Тут его тоже вполне можно применить
    2. Если мы будем использовать отдельный сервис с очередью, то он может отслеживать и записывать только последний статус каждой операции. То есть например если в сервис пришла информация о смене статуса события А на статус 2, а потом через короткий промежуток времени на статус 3, то можно делать только второй апдейт, не тратя время и ресурсы на первый.
    
4. Как можно спроектировать сервис для отслеживания состояния обработки входных JSON по всему pipeline, чтобы избежать подобных проблем? Какие минусы у вашего варианта реализации такого сервиса?

Я бы выбрал третий свой вариант из вопроса номер 2: создать некий мастер сервер, из которого я бы управлял всем пайплайном и обновлением статусов. Минусы у этого способа следующие:
Рано или поздно он может стать боттлнеком всей системы. Хотя в целом основная его нагрузка заключается в работе с бд
Сложнее масштабировать, хотя в целом ничего не мешает иметь несколько таких мастеров, просто каждому отдавать свой пак этих jsonов, чтобы каждый работал только по своим и соответственно и изменял только свои


